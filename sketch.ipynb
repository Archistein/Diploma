{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import utils\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, iterable_dataset\n",
    "\n",
    "ds = load_dataset(\"nielsr/CelebA-faces\", streaming=True)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacesIterDataset(utils.data.IterableDataset):\n",
    "    def __init__(self, \n",
    "                 iterable: iterable_dataset.IterableDataset,\n",
    "                 transforms: A.Compose\n",
    "                ):\n",
    "        self.iterable = iterable\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __iter__(self) -> Iterator[torch.Tensor]:\n",
    "        for item in self.iterable:\n",
    "            image = np.array(item['image'])\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "            yield image\n",
    "\n",
    "transforms = A.Compose([\n",
    "    A.CenterCrop(160, 140, p=1),\n",
    "    A.ToGray(1, p=1),\n",
    "    A.Normalize(mean=0.4375, std=0.2708),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataloader = utils.data.DataLoader(FacesIterDataset(ds, transforms),\n",
    "                              batch_size = 6,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_denormalization(img: torch.Tensor, mean: float = 0.4375, std: float = 0.2708) -> np.ndarray:\n",
    "    return np.clip((img.numpy() * std + mean)*255, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 img_size: tuple[int],\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_layers: tuple[int]\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        \n",
    "        for layer in hidden_layers:\n",
    "            layers.extend([\n",
    "                nn.Conv2d(in_channels, layer, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(layer),\n",
    "                nn.ELU()\n",
    "            ])\n",
    "            in_channels = layer\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        enc_dim = hidden_layers[-1] * ceil(img_size[0] / 2**len(hidden_layers)) * ceil(img_size[1] / 2**len(hidden_layers)) \n",
    "        self.fc_mu = nn.Linear(enc_dim, latent_dim)\n",
    "        self.fc_sigma = nn.Linear(enc_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor]:\n",
    "        x = torch.flatten(self.encoder(x))\n",
    "        \n",
    "        mu = self.fc_mu(x)\n",
    "        sigma = self.fc_sigma(x)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    pass\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 img_size: tuple[int],\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int = 256,\n",
    "                 hidden_layers: tuple[int] = (8, 32, 64, 128)\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(...)\n",
    "        self.decoder = Decoder(...)\n",
    "\n",
    "    def encode(x: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    def decode(mu: torch.Tensor, sigma: torch.Tensor):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
